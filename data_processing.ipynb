{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing and Pre-Processing GENIA Text Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is given in XML format, with the POS of each word identified. Biological entities are also labelled with the type of entity. We parse this data file and tag each word with the POS it is labelled as and also assign a label to it based on whether or not it is a biological entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "data_file_path = './data/GENIAcorpus3.02.merged.xml'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we parse the XML data file to get the POS of each word and determine the semantic biological meaning of each word (if it has one). The words with a biological meaning will be labelled as a 1, and the non-biological words will be labelled with a -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bs4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_words_part_of_speech\u001b[39m(sentence: bs4\u001b[39m.\u001b[39melement\u001b[39m.\u001b[39mTag, words_pos_dict: \u001b[39mdict\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m      2\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m    Extracts words in given sentence and their respective part of speech.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m    Updates words_pos_dict (passed by reference) to contain these words and their POS.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39m        words_pos_dict (dict): The dictionary to update with the words and POS.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     words \u001b[39m=\u001b[39m sentence\u001b[39m.\u001b[39mfind_all(\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bs4' is not defined"
     ]
    }
   ],
   "source": [
    "def get_words_part_of_speech(sentence: bs4.element.Tag, words_pos_dict: dict) -> None:\n",
    "    \"\"\"\n",
    "    Extracts words in given sentence and their respective part of speech.\n",
    "    Updates words_pos_dict (passed by reference) to contain these words and their POS.\n",
    "\n",
    "    Arg:\n",
    "        sentence (bs4.element.Tag): The sentence to extract the words and POS from.\n",
    "        words_pos_dict (dict): The dictionary to update with the words and POS.\n",
    "    \"\"\"\n",
    "    words = sentence.find_all('w')\n",
    "    for word in words:\n",
    "        text = word.text.strip()\n",
    "        if text not in words_pos_dict:\n",
    "            words_pos_dict[text] = set()\n",
    "        words_pos_dict[text].add(word['c'])\n",
    "\n",
    "def get_named_bio_entities(sentence: bs4.element.Tag, named_bio_entities_dict: dict) -> None:\n",
    "    \"\"\"\n",
    "    Extracts named biological entities in given sentence.\n",
    "    Updates named_bio_entities_dict (passed by reference) to contain these entities.\n",
    "\n",
    "    Arg:\n",
    "        sentence (bs4.element.Tag): The sentence to extract the named biological entities from.\n",
    "        named_bio_entities_dict (dict): The dictionary to update with the named biological entities.\n",
    "    \"\"\"\n",
    "    bio_entities = sentence.find_all('cons')\n",
    "    for ent in bio_entities:\n",
    "        text = ent['lex'].strip()\n",
    "        if text not in named_bio_entities_dict:\n",
    "            named_bio_entities_dict[text] = set()\n",
    "        named_bio_entities_dict[text].add(ent['sem'])\n",
    "\n",
    "def extract_data_from_xml(data_file_path: str):\n",
    "    \"\"\"\n",
    "    Extracts the data from the xml file and returns a list of tuples\n",
    "    containing the text and the label.\n",
    "    Note that punctuation marks are kept in the data as was done in the presented paper.\n",
    "    However, they are not attached to any of the words.\n",
    "    \n",
    "    Args:\n",
    "        data_file_path (str): The path to the xml file.\n",
    "        \n",
    "    Returns:\n",
    "        List of tuples containing the text and the label.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    words_pos_dict = dict() # dict of set\n",
    "    named_bio_entities_dict = dict() # dict of set\n",
    "    with open(data_file_path, \"r\") as f:\n",
    "        xml = f.read()\n",
    "        print(\"Parsing XML file with BeautifulSoup...\")\n",
    "        soup = BeautifulSoup(xml, 'xml')\n",
    "        print(\"Parsing Done. Now extracting info...\")\n",
    "        articles = soup.find_all('article')\n",
    "        for art in tqdm(articles, ncols=len(articles)):\n",
    "            print(art.find('bibliomisc').text)\n",
    "            sentences = art.find_all('sentence')\n",
    "            for sent in sentences:\n",
    "                try:\n",
    "                    get_words_part_of_speech(sent, words_pos_dict)\n",
    "                    get_named_bio_entities(sent, named_bio_entities_dict)\n",
    "                except:\n",
    "                    print(\"Error in article: \", art.find('bibliomisc').text)\n",
    "                    return\n",
    "    print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing XML file with BeautifulSoup...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "extract_data_from_xml(data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72f86c46800bdf116255aecb4724685bd63dbc1069855c869a8e3dd17ec92b2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
